import os
import json
import time
from zhipuai import ZhipuAI

# åˆå§‹åŒ–æ™ºè°±AIå®¢æˆ·ç«¯
client = ZhipuAI(api_key="api key")  # è¯·æ›¿æ¢ä¸ºä½ çš„å®é™…API Key


def find_all_json_files(input_dir):
    """
    é€’å½’æŸ¥æ‰¾æ‰€æœ‰JSONæ–‡ä»¶
    """
    json_files = []
    print(f"ğŸ” å¼€å§‹åœ¨ç›®å½•ä¸­æœç´¢JSONæ–‡ä»¶: {input_dir}")

    # ä½¿ç”¨os.walké€’å½’éå†æ‰€æœ‰å­ç›®å½•
    for root, dirs, files in os.walk(input_dir):
        json_files_in_dir = [f for f in files if f.endswith('.json')]
        for file in json_files_in_dir:
            full_path = os.path.join(root, file)
            json_files.append(full_path)

        # æ¯å¤„ç†ä¸€ä¸ªç›®å½•å°±æ‰“å°è¿›åº¦
        if json_files_in_dir:
            print(f"  åœ¨ {root} ä¸­æ‰¾åˆ° {len(json_files_in_dir)} ä¸ªJSONæ–‡ä»¶")

    print(f"âœ… æ€»å…±æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶")
    return json_files


def create_batch_jsonl_with_formula_types(input_dir, output_dir, max_requests_per_file=50000, max_file_size_mb=100):
    """
    åˆ›å»ºå¤šä¸ªBatch APIæ‰€éœ€çš„JSONLæ–‡ä»¶ï¼Œè‡ªåŠ¨åˆ†ç‰‡
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # é€’å½’æŸ¥æ‰¾æ‰€æœ‰JSONæ–‡ä»¶
    all_json_files = find_all_json_files(input_dir)

    if not all_json_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•JSONæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„å’Œæ–‡ä»¶æ ¼å¼")
        return [], 0

    # å®šä¹‰ç®€åŒ–çš„å…¬å¼ç±»å‹åˆ†ç±»ï¼ˆå››å¤§ç±»ï¼‰
    formula_types = {
        "closed_form": "é€šé¡¹å…¬å¼ (closed form)",
        "recurrence": "é€’æ¨å…¬å¼ (recurrence relation)",
        "generating_function": "ç”Ÿæˆå‡½æ•° (generating function)",
        "other": "å…¶ä»–ç±»å‹ (other)"
    }

    file_index = 1
    current_requests = 0
    current_size = 0
    total_requests = 0

    # åˆ›å»ºç¬¬ä¸€ä¸ªJSONLæ–‡ä»¶
    jsonl_file_path = os.path.join(output_dir, f"batch_requests_{file_index}.jsonl")
    f_out = open(jsonl_file_path, 'w', encoding='utf-8')
    jsonl_files = [jsonl_file_path]

    print(f"ğŸ“ å¼€å§‹åˆ›å»ºJSONLæ–‡ä»¶: {jsonl_file_path}")

    # éå†æ‰€æœ‰æ‰¾åˆ°çš„JSONæ–‡ä»¶
    for i, json_file_path in enumerate(all_json_files, 1):
        print(f"ğŸ” å¤„ç†æ–‡ä»¶ ({i}/{len(all_json_files)}): {os.path.basename(json_file_path)}")

        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                seq_data = json.load(f)
        except Exception as e:
            print(f"  âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            continue

        # æ£€æŸ¥å¿…è¦å­—æ®µ
        if not all(key in seq_data for key in ['sequence_id', 'formulas']):
            print(f"  âš ï¸ æ–‡ä»¶ç¼ºå°‘å¿…è¦å­—æ®µï¼Œè·³è¿‡")
            continue

        if not isinstance(seq_data['formulas'], list) or len(seq_data['formulas']) == 0:
            print(f"  âš ï¸ formulaså­—æ®µä¸ºç©ºæˆ–ä¸æ˜¯åˆ—è¡¨ï¼Œè·³è¿‡")
            continue

        print(f"  âœ… åºåˆ—ID: {seq_data['sequence_id']}, å…¬å¼æ•°é‡: {len(seq_data['formulas'])}")

        # æ„å»ºsystem prompt - ä½¿ç”¨ç®€åŒ–çš„å››å¤§ç±»åˆ†ç±»
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°å­¦å…¬å¼è§£æå™¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»ç”¨æˆ·æä¾›çš„æ–‡æœ¬ä¸­ç²¾ç¡®è¯†åˆ«å’Œæå–æ‰€æœ‰æ•°å­¦å…¬å¼ï¼Œå¹¶å¯¹æ¯ä¸ªå…¬å¼è¿›è¡Œåˆ†ç±»ã€‚

è¯·å°†å…¬å¼åˆ†ç±»ä¸ºä»¥ä¸‹å››ç§ç±»å‹ä¹‹ä¸€ï¼š
{json.dumps(formula_types, indent=2, ensure_ascii=False)}

åˆ†ç±»æŒ‡å—ï¼š
1. é€šé¡¹å…¬å¼ (closed_form): ç›´æ¥ç»™å‡ºç¬¬né¡¹çš„è¡¨è¾¾å¼ï¼Œå¦‚ F(n) = Ï†^n/âˆš5 - (1-Ï†)^n/âˆš5
2. é€’æ¨å…¬å¼ (recurrence): æè¿°é¡¹ä¸é¡¹ä¹‹é—´å…³ç³»çš„å…¬å¼ï¼Œå¦‚ F(n) = F(n-1) + F(n-2)
3. ç”Ÿæˆå‡½æ•° (generating_function): ä»¥å¹‚çº§æ•°å½¢å¼è¡¨ç¤ºåºåˆ—çš„å‡½æ•°ï¼Œå¦‚ G.f.: x/(1-x-x^2)
4. å…¶ä»– (other): ä¸å±äºä»¥ä¸Šä¸‰ç±»çš„ä»»ä½•å…¬å¼ï¼Œå¦‚çŸ©é˜µå½¢å¼ã€æ’ç­‰å¼ã€è¿åˆ†æ•°ç­‰

æœ€ç»ˆè¾“å‡ºè¯·ä½¿ç”¨JSONæ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- "sequence_id": åºåˆ—ID
- "extracted_formulas": åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼ŒåŒ…å«:
  - "formula_text": åŸå§‹å…¬å¼æ–‡æœ¬
  - "formula_type": å…¬å¼ç±»å‹ï¼ˆå¿…é¡»ä»ä¸Šè¿°å››ç§ç±»å‹ä¸­é€‰æ‹©ï¼‰
  - "formula_latex": å…¬å¼çš„LaTeXè¡¨ç¤ºï¼ˆå¦‚æœé€‚ç”¨ï¼‰
  - "confidence": ä½ å¯¹åˆ†ç±»çš„ç½®ä¿¡åº¦ï¼ˆ0-1ä¹‹é—´çš„æ•°å€¼ï¼‰

è¯·ç¡®ä¿æå–å’Œåˆ†ç±»å°½å¯èƒ½å‡†ç¡®ã€‚å¯¹äºä¸ç¡®å®šçš„ç±»å‹ï¼Œè¯·é€‰æ‹©"other"ã€‚"""

        # æ„å»ºç”¨æˆ·æ¶ˆæ¯
        user_prompt = f"Sequence ID: {seq_data['sequence_id']}\nFormulas to classify:\n" + "\n".join(
            [f"{i + 1}. {formula}" for i, formula in enumerate(seq_data['formulas'])])

        # æ„é€ è¯·æ±‚ä½“
        request_body = {
            "custom_id": f"request-{total_requests}-{seq_data['sequence_id']}",
            "method": "POST",
            "url": "/v4/chat/completions",
            "body": {
                "model": "glm-4-flash",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.1,
                "max_tokens": 2000,
                "response_format": {"type": "json_object"}
            }
        }

        # è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²å¹¶è®¡ç®—å¤§å°
        request_json = json.dumps(request_body, ensure_ascii=False)
        request_size = len(request_json.encode('utf-8'))

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºæ–°æ–‡ä»¶
        if (current_requests >= max_requests_per_file or
                (current_size + request_size) > max_file_size_mb * 1024 * 1024):
            f_out.close()
            print(f"âœ… å·²åˆ›å»º: {jsonl_file_path} (åŒ…å« {current_requests} ä¸ªè¯·æ±‚, {current_size / 1024 / 1024:.2f} MB)")

            # åˆ›å»ºæ–°æ–‡ä»¶
            file_index += 1
            current_requests = 0
            current_size = 0
            jsonl_file_path = os.path.join(output_dir, f"batch_requests_{file_index}.jsonl")
            f_out = open(jsonl_file_path, 'w', encoding='utf-8')
            jsonl_files.append(jsonl_file_path)
            print(f"ğŸ“ å¼€å§‹åˆ›å»ºæ–°æ–‡ä»¶: {jsonl_file_path}")

        # å†™å…¥è¯·æ±‚
        f_out.write(request_json + '\n')
        current_requests += 1
        current_size += request_size
        total_requests += 1

        if total_requests % 100 == 0:
            print(f"ğŸ“Š å·²å¤„ç† {total_requests} ä¸ªè¯·æ±‚")

    # å…³é—­æœ€åä¸€ä¸ªæ–‡ä»¶
    f_out.close()
    print(f"âœ… å·²åˆ›å»º: {jsonl_file_path} (åŒ…å« {current_requests} ä¸ªè¯·æ±‚, {current_size / 1024 / 1024:.2f} MB)")
    print(f"ğŸ“Š æ€»å…±åˆ›å»º {len(jsonl_files)} ä¸ªJSONLæ–‡ä»¶ï¼ŒåŒ…å« {total_requests} ä¸ªè¯·æ±‚")

    return jsonl_files, total_requests


def validate_jsonl_file(file_path):
    """éªŒè¯JSONLæ–‡ä»¶æ ¼å¼"""
    print(f"ğŸ” éªŒè¯JSONLæ–‡ä»¶: {file_path}")
    line_count = 0
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for i, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                try:
                    data = json.loads(line)
                    # æ£€æŸ¥å¿…éœ€å­—æ®µ
                    if not all(key in data for key in ["custom_id", "method", "url", "body"]):
                        print(f"âŒ ç¬¬ {i} è¡Œç¼ºå°‘å¿…éœ€å­—æ®µ")
                        return False
                    line_count += 1
                except json.JSONDecodeError as e:
                    print(f"âŒ ç¬¬ {i} è¡ŒJSONæ ¼å¼é”™è¯¯: {e}")
                    return False
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return False

    print(f"âœ… JSONLæ–‡ä»¶éªŒè¯é€šè¿‡ï¼ŒåŒ…å« {line_count} ä¸ªæœ‰æ•ˆè¯·æ±‚")
    return line_count > 0  # ç¡®ä¿æ–‡ä»¶ä¸ä¸ºç©º


def submit_batch_task_with_retry(jsonl_file_path, max_retries=3):
    """å¸¦é‡è¯•æœºåˆ¶çš„ä»»åŠ¡æäº¤"""
    for attempt in range(max_retries):
        try:
            print(f"ğŸ”„ å°è¯• {attempt + 1}/{max_retries}: ä¸Šä¼ æ–‡ä»¶ {os.path.basename(jsonl_file_path)}")

            # ä¸Šä¼ æ–‡ä»¶
            with open(jsonl_file_path, "rb") as f:
                upload_result = client.files.create(file=f, purpose="batch")
            file_id = upload_result.id
            print(f"  âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼ŒID: {file_id}")

            # åˆ›å»ºBatchä»»åŠ¡
            batch_create_result = client.batches.create(
                input_file_id=file_id,
                endpoint="/v4/chat/completions",
                completion_window="24h",
                metadata={
                    "description": "OEISå…¬å¼åˆ†ç±»ä»»åŠ¡ï¼ˆå››å¤§ç±»ï¼‰",
                    "original_filename": os.path.basename(jsonl_file_path)
                }
            )

            batch_id = batch_create_result.id
            print(f"  âœ… Batchä»»åŠ¡åˆ›å»ºæˆåŠŸï¼ŒID: {batch_id}")
            return batch_id

        except Exception as e:
            print(f"  âŒ å°è¯• {attempt + 1} å¤±è´¥: {e}")
            if attempt < max_retries - 1:
                wait_time = 5 * (attempt + 1)  # é€’å¢ç­‰å¾…æ—¶é—´
                print(f"  â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)

    return None


def submit_batch_tasks(jsonl_files, task_id_file):
    """æäº¤å¤šä¸ªæ‰¹é‡ä»»åŠ¡å¹¶ä¿å­˜æ‰€æœ‰ä»»åŠ¡ID"""
    task_ids = []
    successful_files = 0

    for i, jsonl_file_path in enumerate(jsonl_files, 1):
        print(f"\nğŸ“‹ å¤„ç†æ–‡ä»¶ {i}/{len(jsonl_files)}: {os.path.basename(jsonl_file_path)}")

        # éªŒè¯æ–‡ä»¶æ ¼å¼
        if not validate_jsonl_file(jsonl_file_path):
            print(f"  âš ï¸ æ–‡ä»¶éªŒè¯å¤±è´¥ï¼Œè·³è¿‡: {jsonl_file_path}")
            continue

        # æäº¤ä»»åŠ¡ï¼ˆå¸¦é‡è¯•ï¼‰
        batch_id = submit_batch_task_with_retry(jsonl_file_path)

        if batch_id:
            task_ids.append(batch_id)
            successful_files += 1
            print(f"  âœ… æˆåŠŸåˆ›å»ºä»»åŠ¡: {batch_id}")
        else:
            print(f"  âŒ æ‰€æœ‰é‡è¯•å‡å¤±è´¥: {jsonl_file_path}")

    # ä¿å­˜æ‰€æœ‰ä»»åŠ¡IDåˆ°æ–‡ä»¶
    if task_ids:
        with open(task_id_file, 'w') as f:
            for task_id in task_ids:
                f.write(task_id + '\n')

        print(f"\nğŸ“ æˆåŠŸåˆ›å»º {successful_files} ä¸ªä»»åŠ¡ï¼ŒIDå·²ä¿å­˜åˆ°: {task_id_file}")
    else:
        print("\nâŒ æœªèƒ½åˆ›å»ºä»»ä½•ä»»åŠ¡")

    return task_ids


if __name__ == "__main__":
    # é…ç½®è·¯å¾„
    input_directory = "D:/nn/oeis_onlyclean_json"  # ä½ çš„JSONæ–‡ä»¶ç›®å½•
    output_directory = "batch_requests2"  # è¾“å‡ºJSONLæ–‡ä»¶çš„ç›®å½•
    task_id_file = "batch_task_ids2.txt"  # ä¿å­˜ä»»åŠ¡IDçš„æ–‡ä»¶

    print("ğŸš€ å¼€å§‹Batchä»»åŠ¡æäº¤æµç¨‹...")

    # 1. åˆ›å»ºJSONLè¯·æ±‚æ–‡ä»¶
    print("\n" + "=" * 50)
    print("æ­¥éª¤1: åˆ›å»ºJSONLè¯·æ±‚æ–‡ä»¶")
    print("=" * 50)
    jsonl_files, total_requests = create_batch_jsonl_with_formula_types(
        input_directory,
        output_directory,
        max_requests_per_file=50000,  # æ¯ä¸ªæ–‡ä»¶æœ€å¤š50,000ä¸ªè¯·æ±‚
        max_file_size_mb=100  # æ¯ä¸ªæ–‡ä»¶æœ€å¤§100MB
    )

    if total_requests == 0:
        print("âŒ æ²¡æœ‰åˆ›å»ºä»»ä½•è¯·æ±‚ï¼Œè¯·æ£€æŸ¥JSONæ–‡ä»¶æ ¼å¼å’Œå†…å®¹")
        exit(1)

    # 2. æäº¤æ‰€æœ‰ä»»åŠ¡
    print("\n" + "=" * 50)
    print("æ­¥éª¤2: æäº¤Batchä»»åŠ¡")
    print("=" * 50)
    task_ids = submit_batch_tasks(jsonl_files, task_id_file)

    print("\n" + "=" * 50)
    print("ä»»åŠ¡æäº¤æ‘˜è¦")
    print("=" * 50)
    print(f"â€¢ åˆ›å»ºçš„JSONLæ–‡ä»¶æ•°: {len(jsonl_files)}")
    print(f"â€¢ æ€»è¯·æ±‚æ•°: {total_requests}")
    print(f"â€¢ æˆåŠŸåˆ›å»ºçš„ä»»åŠ¡æ•°: {len(task_ids)}")
    print(f"â€¢ ä»»åŠ¡IDæ–‡ä»¶: {task_id_file}")

    if task_ids:
        print("\nğŸ‰ ä»»åŠ¡æäº¤å®Œæˆï¼")
    else:

        print("\nâŒ ä»»åŠ¡æäº¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
